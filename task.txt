Hi Karlo,

Here's the the test task. 

Please stop working after 3 hours, and contact me.

I'd like you to submit the results to me before 18:00 CET next Wednesday. If 
this is not possible please let me know.

If you've any questions please contact me:
keith@dancingtext.com
Phone: + 44 77 4955 7230
Skype: keithmmcdonnell

= Test task: simple KNN applied to QQQ 1 min data

1. Download dataset (0.5 hrs) needed 50 minutes

Create script that:
- takes ticker as an argument
- downloads data set from google finance
- saves output to a csv

eg: python download.py 'QQQ' -> QQQ.csv

Here's the google finance url; note the location of the ticker QQQ:
http://www.google.com/finance/getprices?q=QQQ&i=60&p=2d&f=d,o,h,l,c,v

2. Build a simple KNN (2 hrs)

Please use the source code from Machine Learning in Action [MLIA]. I'll reference
secions of the book thusly: MLIA 2.2.4. 

Here's a link to my copy of the book: 
http://dl.dropbox.com/u/78178962/Machine%20Learning%20in%20Action.pdf

Here's the source code for ch.2:
https://github.com/kmcd/machine_learning_in_action/tree/master/Ch02

Most of the functionality you need is in this file:
https://github.com/kmcd/machine_learning_in_action/blob/master/Ch02/kNN.py

Create a script that takes CSV & outputs KNN test results to STDOUT, as shown 
in [MLIA 2.2.4];

eg python knn.py 'QQQ.csv' ->
  the classifier came
  ...
  total error
  
Notes:
- Use csv from step 1
- Divide data set into test (10%) & training (90%) sets
- Use Euclidean distance
- Normalise test set data only [MLIA 2.2.3]

Please classify a point as LONG when:
  - *next* point is has a low > $0.03
  - next point has high/close >= $0.03
  
Where a point is 1 csv row corresponding to a data for last minute.

If you get stuck or a step takes too long, you can skip it. The point of the 
exercise is to output results (even if incorrect). Just let me know what you
skipped when submitting your work.
  
3. Questions (0.5 hrs)

- Please explain how you would use a regualarizer with KNN
- What are KNN specific pitfalls to be aware of?
- Have you any suggestions for:
  * Normalising the data
  * expanding the input data (correlation, auto-correllation, more time frames)
  * Dimension reduction after data expansion
- Can you suggest other ML algos/methods that might be more appropriate
- Can you explain how you approach the whole ML process; collect, prepare, test,
  train, validate etc.
